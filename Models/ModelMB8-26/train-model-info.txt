    all_dataset = create_tf_dataset(["./Data/NewerLogs-Inc-ModelBot/Logs/Vectors/",
                                     "./Data/NewerLogs60k/Logs2/Vectors/",
                                     "./Logs/Vectors/",
                                     "./Logs2/Vectors"],
                                    add_channel=False,
                                    norm=False
                                    )
    print(all_dataset.take(1).as_numpy_iterator().next())
    model = get_nn_model()
    VALIDATION_LENGTH = 100000
    TEST_LENGTH = 100000
    BATCH_SIZE = 4096
    SHUFFLE_BUFFER_SIZE = 100000
    
    checkpoint_filepath = './model-checkpoints/'
    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_filepath,
    save_weights_only=True,
    monitor='val_loss',
    mode='min',
    save_best_only=True)
    
    validation_ds = all_dataset.take(VALIDATION_LENGTH).batch(BATCH_SIZE)
    
    test_ds = all_dataset.skip(VALIDATION_LENGTH).take(TEST_LENGTH).batch(BATCH_SIZE)
    
    train_ds = all_dataset.skip(VALIDATION_LENGTH+TEST_LENGTH).shuffle(SHUFFLE_BUFFER_SIZE).prefetch(tf.data.AUTOTUNE).batch(BATCH_SIZE)#Add shuffle for NN
    
    early_stopping_cb = tf.keras.callbacks.EarlyStopping(min_delta=0, patience=10, restore_best_weights=True, start_from_epoch=10)
    if os.path.exists("tensorboard-log/"):
        raise Exception("Tensorboard log directory already exists")
    tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir="tensorboard-log/",histogram_freq=1,profile_batch=2)
    
    model.fit(x=train_ds, validation_data=validation_ds, epochs=100, callbacks=[early_stopping_cb, tensorboard_cb, model_checkpoint_callback])
    
    model.evaluate(test_ds, verbose=1)
    
    model.save("model.h5")